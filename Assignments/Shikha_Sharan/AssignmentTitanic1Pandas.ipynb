{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variable|Definition|Key|\n",
    "|---|---|---|\n",
    "|survival|Survival|0 = No, 1 = Yes|\n",
    "|pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|gender|gender ||\n",
    "|Age |Age in years| |\n",
    "|sibsp |number of siblings / spouses aboard|\t|\n",
    "|parch |number of parents / children aboard| |\n",
    "|ticket|Ticket number ||\n",
    "|fare | fare| \t|\n",
    "|cabin |Cabin number|\t|\n",
    "|embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "|boat | Lifeboat||\n",
    "|body | Body Identification Number||\n",
    "|home.dest| Home/destination||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read data and describe it\n",
    "- Find columns with missingdata\n",
    "- Print shape of dataset\n",
    "- drop columns with more than 25% missing data\n",
    "- drop columns having independent values(which do not affect the survival rate).\n",
    "\n",
    "\n",
    "- check data types of all columns\n",
    "- convert price to numeric\n",
    "- find columns still having missing/na values and also count of missing data\n",
    "- fill na with mean for fare and age column column.\n",
    "- drop na values for embarked column.\n",
    "- dump the dataframe to a csv file 'titanic_filtered.csv'.\n",
    "\n",
    "\n",
    "- for surviced column replace 0 with D and 1 with A\n",
    "- find the frequency of different values in survived column\n",
    "- group by gender and survived and see the counts in each category\n",
    "- find different pclass and no of people in each class\n",
    "\n",
    "- find top 5 people with highest values of age. Count no of male and females in the top 5\n",
    "- find max age male and female who survived\n",
    "- get average age by gender\n",
    "- get average age by people survived vs not-survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  pclass  survived  \\\n",
      "0           0       1         1   \n",
      "1           1       1         1   \n",
      "2           2       1         0   \n",
      "3           3       1         0   \n",
      "4           4       1         0   \n",
      "\n",
      "                                              name  gender      age  sibsp  \\\n",
      "0                    Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
      "1                   Allison, Master. Hudson Trevor    male   0.9167      1   \n",
      "2                     Allison, Miss. Helen Loraine  female   2.0000      1   \n",
      "3             Allison, Mr. Hudson Joshua Creighton    male  30.0000      1   \n",
      "4  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000      1   \n",
      "\n",
      "   parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0      0   24160  $211.34        B5        S    2    NaN   \n",
      "1      2  113781  $151.55   C22 C26        S   11    NaN   \n",
      "2      2  113781  $151.55   C22 C26        S  NaN    NaN   \n",
      "3      2  113781  $151.55   C22 C26        S  NaN  135.0   \n",
      "4      2  113781  $151.55   C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\Shikha\\Desktop\\dsc_weekday_2020_09_24 - Copy\\submitted assignments\\titanic_dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'pclass', 'survived', 'name', 'gender', 'age', 'sibsp',\n",
      "       'parch', 'ticket', 'fare', 'cabin', 'embarked', 'boat', 'body',\n",
      "       'home.dest'],\n",
      "      dtype='object')\n",
      "15\n",
      "(1309, 15)\n"
     ]
    }
   ],
   "source": [
    "#Find columns with missingdata\n",
    "print(df.columns)\n",
    "print(len(df.columns))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  pclass  survived  \\\n",
      "0           0       1         1   \n",
      "1           1       1         1   \n",
      "2           2       1         0   \n",
      "3           3       1         0   \n",
      "4           4       1         0   \n",
      "\n",
      "                                              name  gender      age  sibsp  \\\n",
      "0                    Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
      "1                   Allison, Master. Hudson Trevor    male   0.9167      1   \n",
      "2                     Allison, Miss. Helen Loraine  female   2.0000      1   \n",
      "3             Allison, Mr. Hudson Joshua Creighton    male  30.0000      1   \n",
      "4  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000      1   \n",
      "\n",
      "   parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0      0   24160  $211.34        B5        S    2    NaN   \n",
      "1      2  113781  $151.55   C22 C26        S   11    NaN   \n",
      "2      2  113781  $151.55   C22 C26        S  NaN    NaN   \n",
      "3      2  113781  $151.55   C22 C26        S  NaN  135.0   \n",
      "4      2  113781  $151.55   C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n",
      "\n",
      "        Unnamed: 0       pclass     survived          age        sibsp  \\\n",
      "count  1309.000000  1309.000000  1309.000000  1046.000000  1309.000000   \n",
      "mean    654.000000     2.294882     0.381971    29.881135     0.498854   \n",
      "std     378.020061     0.837836     0.486055    14.413500     1.041658   \n",
      "min       0.000000     1.000000     0.000000     0.166700     0.000000   \n",
      "25%     327.000000     2.000000     0.000000    21.000000     0.000000   \n",
      "50%     654.000000     3.000000     0.000000    28.000000     0.000000   \n",
      "75%     981.000000     3.000000     1.000000    39.000000     1.000000   \n",
      "max    1308.000000     3.000000     1.000000    80.000000     8.000000   \n",
      "\n",
      "             parch        body  \n",
      "count  1309.000000  121.000000  \n",
      "mean      0.385027  160.809917  \n",
      "std       0.865560   97.696922  \n",
      "min       0.000000    1.000000  \n",
      "25%       0.000000   72.000000  \n",
      "50%       0.000000  155.000000  \n",
      "75%       0.000000  256.000000  \n",
      "max       9.000000  328.000000  \n",
      "\n",
      "         Unnamed: 0       pclass     survived                  name gender  \\\n",
      "count   1309.000000  1309.000000  1309.000000                  1309   1309   \n",
      "unique          NaN          NaN          NaN                  1307      2   \n",
      "top             NaN          NaN          NaN  Connolly, Miss. Kate   male   \n",
      "freq            NaN          NaN          NaN                     2    843   \n",
      "mean     654.000000     2.294882     0.381971                   NaN    NaN   \n",
      "std      378.020061     0.837836     0.486055                   NaN    NaN   \n",
      "min        0.000000     1.000000     0.000000                   NaN    NaN   \n",
      "25%      327.000000     2.000000     0.000000                   NaN    NaN   \n",
      "50%      654.000000     3.000000     0.000000                   NaN    NaN   \n",
      "75%      981.000000     3.000000     1.000000                   NaN    NaN   \n",
      "max     1308.000000     3.000000     1.000000                   NaN    NaN   \n",
      "\n",
      "                age        sibsp        parch    ticket    fare        cabin  \\\n",
      "count   1046.000000  1309.000000  1309.000000      1309    1308          295   \n",
      "unique          NaN          NaN          NaN       929     263          186   \n",
      "top             NaN          NaN          NaN  CA. 2343  $8.05   C23 C25 C27   \n",
      "freq            NaN          NaN          NaN        11      60            6   \n",
      "mean      29.881135     0.498854     0.385027       NaN     NaN          NaN   \n",
      "std       14.413500     1.041658     0.865560       NaN     NaN          NaN   \n",
      "min        0.166700     0.000000     0.000000       NaN     NaN          NaN   \n",
      "25%       21.000000     0.000000     0.000000       NaN     NaN          NaN   \n",
      "50%       28.000000     0.000000     0.000000       NaN     NaN          NaN   \n",
      "75%       39.000000     1.000000     0.000000       NaN     NaN          NaN   \n",
      "max       80.000000     8.000000     9.000000       NaN     NaN          NaN   \n",
      "\n",
      "       embarked boat        body     home.dest  \n",
      "count      1307  486  121.000000           745  \n",
      "unique        3   27         NaN           369  \n",
      "top           S   13         NaN  New York, NY  \n",
      "freq        914   39         NaN            64  \n",
      "mean        NaN  NaN  160.809917           NaN  \n",
      "std         NaN  NaN   97.696922           NaN  \n",
      "min         NaN  NaN    1.000000           NaN  \n",
      "25%         NaN  NaN   72.000000           NaN  \n",
      "50%         NaN  NaN  155.000000           NaN  \n",
      "75%         NaN  NaN  256.000000           NaN  \n",
      "max         NaN  NaN  328.000000           NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print()\n",
    "print(df.describe())\n",
    "print()\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    1307\n",
       "pclass        1307\n",
       "survived      1307\n",
       "name          1307\n",
       "gender        1307\n",
       "age           1307\n",
       "sibsp         1307\n",
       "parch         1307\n",
       "ticket        1307\n",
       "fare          1307\n",
       "embarked      1307\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    False\n",
      "pclass        False\n",
      "survived      False\n",
      "name          False\n",
      "gender        False\n",
      "age           False\n",
      "sibsp         False\n",
      "parch         False\n",
      "ticket        False\n",
      "fare          False\n",
      "embarked      False\n",
      "dtype: bool\n",
      "\n",
      "Unnamed: 0    1307\n",
      "pclass        1307\n",
      "survived      1307\n",
      "name          1307\n",
      "gender        1307\n",
      "age           1307\n",
      "sibsp         1307\n",
      "parch         1307\n",
      "ticket        1307\n",
      "fare          1307\n",
      "embarked      1307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().any())\n",
    "print()\n",
    "print(df.notna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0       0\n",
      "pclass           0\n",
      "survived         0\n",
      "name             0\n",
      "gender           0\n",
      "age            263\n",
      "sibsp            0\n",
      "parch            0\n",
      "ticket           0\n",
      "fare             1\n",
      "cabin         1014\n",
      "embarked         2\n",
      "boat           823\n",
      "body          1188\n",
      "home.dest      564\n",
      "dtype: int64\n",
      "1309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0.000000\n",
       "pclass         0.000000\n",
       "survived       0.000000\n",
       "name           0.000000\n",
       "gender         0.000000\n",
       "age           20.091673\n",
       "sibsp          0.000000\n",
       "parch          0.000000\n",
       "ticket         0.000000\n",
       "fare           0.076394\n",
       "cabin         77.463713\n",
       "embarked       0.152788\n",
       "boat          62.872422\n",
       "body          90.756303\n",
       "home.dest     43.086325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with more than 25% missing data\n",
    "print(df.isna().sum())\n",
    "print(df.shape[0])\n",
    "#dropping data having more than 25% means dropping data which have less than 75% data\n",
    "(df.isna().sum()/df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>$211.34</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pclass  survived  \\\n",
       "0           0       1         1   \n",
       "1           1       1         1   \n",
       "2           2       1         0   \n",
       "3           3       1         0   \n",
       "4           4       1         0   \n",
       "\n",
       "                                              name  gender      age  sibsp  \\\n",
       "0                    Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
       "1                   Allison, Master. Hudson Trevor    male   0.9167      1   \n",
       "2                     Allison, Miss. Helen Loraine  female   2.0000      1   \n",
       "3             Allison, Mr. Hudson Joshua Creighton    male  30.0000      1   \n",
       "4  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000      1   \n",
       "\n",
       "   parch  ticket      fare embarked  \n",
       "0      0   24160  $211.34         S  \n",
       "1      2  113781  $151.55         S  \n",
       "2      2  113781  $151.55         S  \n",
       "3      2  113781  $151.55         S  \n",
       "4      2  113781  $151.55         S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns with more than 25% missing data\n",
    "df.dropna(thresh=(0.75*df.shape[0]),axis=1,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>$211.34</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>$151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pclass  survived  \\\n",
       "0           0       1         1   \n",
       "1           1       1         1   \n",
       "2           2       1         0   \n",
       "3           3       1         0   \n",
       "4           4       1         0   \n",
       "\n",
       "                                              name  gender      age  sibsp  \\\n",
       "0                    Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
       "1                   Allison, Master. Hudson Trevor    male   0.9167      1   \n",
       "2                     Allison, Miss. Helen Loraine  female   2.0000      1   \n",
       "3             Allison, Mr. Hudson Joshua Creighton    male  30.0000      1   \n",
       "4  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000      1   \n",
       "\n",
       "   parch  ticket      fare embarked  \n",
       "0      0   24160  $211.34         S  \n",
       "1      2  113781  $151.55         S  \n",
       "2      2  113781  $151.55         S  \n",
       "3      2  113781  $151.55         S  \n",
       "4      2  113781  $151.55         S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns having independent values(which do not affect the survival rate).\n",
    "#df.drop(columns=['Unnamed: 0'],inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "pclass          int64\n",
       "survived        int64\n",
       "name           object\n",
       "gender         object\n",
       "age           float64\n",
       "sibsp           int64\n",
       "parch           int64\n",
       "ticket         object\n",
       "fare           object\n",
       "embarked       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types of all columns\n",
    "df.columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert price to numeric\n",
    "df.fare\n",
    "#df.fare.str[1:].astype('float')\n",
    "#df.fare.str.replace(\"$\", \"\").astype('float')\n",
    "df.fare=df.fare.replace(r\"\\$\",\"\",regex = True).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       211.34\n",
       "1       151.55\n",
       "2       151.55\n",
       "3       151.55\n",
       "4       151.55\n",
       "         ...  \n",
       "1304     14.45\n",
       "1305     14.45\n",
       "1306      7.23\n",
       "1307      7.23\n",
       "1308      7.88\n",
       "Name: fare, Length: 1309, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "gender          0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "embarked        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find columns still having missing/na values and also count of missing data\n",
    "df.count()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DatetimeProperties in module pandas.core.indexes.accessors object:\n",
      "\n",
      "class DatetimeProperties(Properties)\n",
      " |  DatetimeProperties(data, orig)\n",
      " |  \n",
      " |  Accessor object for datetimelike properties of the Series values.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> s.dt.hour\n",
      " |  >>> s.dt.second\n",
      " |  >>> s.dt.quarter\n",
      " |  \n",
      " |  Returns a Series indexed like the original Series.\n",
      " |  Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DatetimeProperties\n",
      " |      Properties\n",
      " |      pandas.core.accessor.PandasDelegate\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.NoNewAttributesMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  ceil(self, *args, **kwargs)\n",
      " |      Perform ceil operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to ceil the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.ceil('H')\n",
      " |      DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 13:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.ceil(\"H\")\n",
      " |      0   2018-01-01 12:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 13:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  day_name(self, *args, **kwargs)\n",
      " |      Return the day names of the DateTimeIndex with specified locale.\n",
      " |      \n",
      " |      .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      locale : str, optional\n",
      " |          Locale determining the language in which to return the day name.\n",
      " |          Default is English locale.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of day names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      >>> idx.day_name()\n",
      " |      Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')\n",
      " |  \n",
      " |  floor(self, *args, **kwargs)\n",
      " |      Perform floor operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to floor the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.floor('H')\n",
      " |      DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.floor(\"H\")\n",
      " |      0   2018-01-01 11:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 12:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  month_name(self, *args, **kwargs)\n",
      " |      Return the month names of the DateTimeIndex with specified locale.\n",
      " |      \n",
      " |      .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      locale : str, optional\n",
      " |          Locale determining the language in which to return the month name.\n",
      " |          Default is English locale.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of month names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2018-01', freq='M', periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],\n",
      " |                    dtype='datetime64[ns]', freq='M')\n",
      " |      >>> idx.month_name()\n",
      " |      Index(['January', 'February', 'March'], dtype='object')\n",
      " |  \n",
      " |  normalize(self, *args, **kwargs)\n",
      " |      Convert times to midnight.\n",
      " |      \n",
      " |      The time component of the date-time is converted to midnight i.e.\n",
      " |      00:00:00. This is useful in cases, when the time does not matter.\n",
      " |      Length is unaltered. The timezones are unaffected.\n",
      " |      \n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on Datetime Array/Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeArray, DatetimeIndex or Series\n",
      " |          The same type as the original data. Series will have the same\n",
      " |          name and index. DatetimeIndex will have the same name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      floor : Floor the datetimes to the specified freq.\n",
      " |      ceil : Ceil the datetimes to the specified freq.\n",
      " |      round : Round the datetimes to the specified freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2014-08-01 10:00', freq='H',\n",
      " |      ...                     periods=3, tz='Asia/Calcutta')\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2014-08-01 10:00:00+05:30',\n",
      " |                     '2014-08-01 11:00:00+05:30',\n",
      " |                     '2014-08-01 12:00:00+05:30'],\n",
      " |                      dtype='datetime64[ns, Asia/Calcutta]', freq='H')\n",
      " |      >>> idx.normalize()\n",
      " |      DatetimeIndex(['2014-08-01 00:00:00+05:30',\n",
      " |                     '2014-08-01 00:00:00+05:30',\n",
      " |                     '2014-08-01 00:00:00+05:30'],\n",
      " |                     dtype='datetime64[ns, Asia/Calcutta]', freq=None)\n",
      " |  \n",
      " |  round(self, *args, **kwargs)\n",
      " |      Perform round operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to round the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.round('H')\n",
      " |      DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.round(\"H\")\n",
      " |      0   2018-01-01 12:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 12:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  strftime(self, *args, **kwargs)\n",
      " |      Convert to Index using specified date_format.\n",
      " |      \n",
      " |      Return an Index of formatted strings specified by date_format, which\n",
      " |      supports the same string format as the python standard library. Details\n",
      " |      of the string format can be found in `python string format\n",
      " |      doc <https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior>`__.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      date_format : str\n",
      " |          Date format string (e.g. \"%Y-%m-%d\").\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          NumPy ndarray of formatted strings.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert the given argument to datetime.\n",
      " |      DatetimeIndex.normalize : Return DatetimeIndex with times to midnight.\n",
      " |      DatetimeIndex.round : Round the DatetimeIndex to the specified freq.\n",
      " |      DatetimeIndex.floor : Floor the DatetimeIndex to the specified freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> rng = pd.date_range(pd.Timestamp(\"2018-03-10 09:00\"),\n",
      " |      ...                     periods=3, freq='s')\n",
      " |      >>> rng.strftime('%B %d, %Y, %r')\n",
      " |      Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',\n",
      " |             'March 10, 2018, 09:00:02 AM'],\n",
      " |            dtype='object')\n",
      " |  \n",
      " |  to_period(self, *args, **kwargs)\n",
      " |      Cast to PeriodArray/Index at a particular frequency.\n",
      " |      \n",
      " |      Converts DatetimeArray/Index to PeriodArray/Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset, optional\n",
      " |          One of pandas' :ref:`offset strings <timeseries.offset_aliases>`\n",
      " |          or an Offset object. Will be inferred by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      PeriodArray/Index\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When converting a DatetimeArray/Index with non-regular values,\n",
      " |          so that a frequency cannot be inferred.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      PeriodIndex: Immutable ndarray holding ordinal values.\n",
      " |      DatetimeIndex.to_pydatetime: Return DatetimeIndex as object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"y\": [1, 2, 3]},\n",
      " |      ...                   index=pd.to_datetime([\"2000-03-31 00:00:00\",\n",
      " |      ...                                         \"2000-05-31 00:00:00\",\n",
      " |      ...                                         \"2000-08-31 00:00:00\"]))\n",
      " |      >>> df.index.to_period(\"M\")\n",
      " |      PeriodIndex(['2000-03', '2000-05', '2000-08'],\n",
      " |                  dtype='period[M]', freq='M')\n",
      " |      \n",
      " |      Infer the daily frequency\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-01-01\", periods=2)\n",
      " |      >>> idx.to_period()\n",
      " |      PeriodIndex(['2017-01-01', '2017-01-02'],\n",
      " |                  dtype='period[D]', freq='D')\n",
      " |  \n",
      " |  to_pydatetime(self)\n",
      " |      Return the data as an array of native Python datetime objects.\n",
      " |      \n",
      " |      Timezone information is retained if present.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         Python's datetime uses microsecond resolution, which is lower than\n",
      " |         pandas (nanosecond). The values are truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Object dtype array containing native Python datetime objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      datetime.datetime : Standard library value for a datetime.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(pd.date_range('20180310', periods=2))\n",
      " |      >>> s\n",
      " |      0   2018-03-10\n",
      " |      1   2018-03-11\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> s.dt.to_pydatetime()\n",
      " |      array([datetime.datetime(2018, 3, 10, 0, 0),\n",
      " |             datetime.datetime(2018, 3, 11, 0, 0)], dtype=object)\n",
      " |      \n",
      " |      pandas' nanosecond precision is truncated to microseconds.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range('20180310', periods=2, freq='ns'))\n",
      " |      >>> s\n",
      " |      0   2018-03-10 00:00:00.000000000\n",
      " |      1   2018-03-10 00:00:00.000000001\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> s.dt.to_pydatetime()\n",
      " |      array([datetime.datetime(2018, 3, 10, 0, 0),\n",
      " |             datetime.datetime(2018, 3, 10, 0, 0)], dtype=object)\n",
      " |  \n",
      " |  tz_convert(self, *args, **kwargs)\n",
      " |      Convert tz-aware Datetime Array/Index from one time zone to another.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str, pytz.timezone, dateutil.tz.tzfile or None\n",
      " |          Time zone for time. Corresponding timestamps would be converted\n",
      " |          to this time zone of the Datetime Array/Index. A `tz` of None will\n",
      " |          convert to UTC and remove the timezone information.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Array or Index\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If Datetime Array/Index is tz-naive.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DatetimeIndex.tz : A timezone that has a variable offset from UTC.\n",
      " |      DatetimeIndex.tz_localize : Localize tz-naive DatetimeIndex to a\n",
      " |          given time zone, or remove timezone from a tz-aware DatetimeIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      With the `tz` parameter, we can change the DatetimeIndex\n",
      " |      to other time zones:\n",
      " |      \n",
      " |      >>> dti = pd.date_range(start='2014-08-01 09:00',\n",
      " |      ...                     freq='H', periods=3, tz='Europe/Berlin')\n",
      " |      \n",
      " |      >>> dti\n",
      " |      DatetimeIndex(['2014-08-01 09:00:00+02:00',\n",
      " |                     '2014-08-01 10:00:00+02:00',\n",
      " |                     '2014-08-01 11:00:00+02:00'],\n",
      " |                    dtype='datetime64[ns, Europe/Berlin]', freq='H')\n",
      " |      \n",
      " |      >>> dti.tz_convert('US/Central')\n",
      " |      DatetimeIndex(['2014-08-01 02:00:00-05:00',\n",
      " |                     '2014-08-01 03:00:00-05:00',\n",
      " |                     '2014-08-01 04:00:00-05:00'],\n",
      " |                    dtype='datetime64[ns, US/Central]', freq='H')\n",
      " |      \n",
      " |      With the ``tz=None``, we can remove the timezone (after converting\n",
      " |      to UTC if necessary):\n",
      " |      \n",
      " |      >>> dti = pd.date_range(start='2014-08-01 09:00', freq='H',\n",
      " |      ...                     periods=3, tz='Europe/Berlin')\n",
      " |      \n",
      " |      >>> dti\n",
      " |      DatetimeIndex(['2014-08-01 09:00:00+02:00',\n",
      " |                     '2014-08-01 10:00:00+02:00',\n",
      " |                     '2014-08-01 11:00:00+02:00'],\n",
      " |                      dtype='datetime64[ns, Europe/Berlin]', freq='H')\n",
      " |      \n",
      " |      >>> dti.tz_convert(None)\n",
      " |      DatetimeIndex(['2014-08-01 07:00:00',\n",
      " |                     '2014-08-01 08:00:00',\n",
      " |                     '2014-08-01 09:00:00'],\n",
      " |                      dtype='datetime64[ns]', freq='H')\n",
      " |  \n",
      " |  tz_localize(self, *args, **kwargs)\n",
      " |      Localize tz-naive Datetime Array/Index to tz-aware\n",
      " |      Datetime Array/Index.\n",
      " |      \n",
      " |      This method takes a time zone (tz) naive Datetime Array/Index object\n",
      " |      and makes this time zone aware. It does not move the time to another\n",
      " |      time zone.\n",
      " |      Time zone localization helps to switch from time zone aware to time\n",
      " |      zone unaware objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str, pytz.timezone, dateutil.tz.tzfile or None\n",
      " |          Time zone to convert timestamps to. Passing ``None`` will\n",
      " |          remove the time zone information preserving local time.\n",
      " |      ambiguous : 'infer', 'NaT', bool array, default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False signifies a\n",
      " |            non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward, 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as self\n",
      " |          Array/Index converted to the specified time zone.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the Datetime Array/Index is tz-aware and tz is not None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DatetimeIndex.tz_convert : Convert tz-aware DatetimeIndex from\n",
      " |          one time zone to another.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)\n",
      " |      >>> tz_naive\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',\n",
      " |                     '2018-03-03 09:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      Localize DatetimeIndex in US/Eastern time zone:\n",
      " |      \n",
      " |      >>> tz_aware = tz_naive.tz_localize(tz='US/Eastern')\n",
      " |      >>> tz_aware\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00-05:00',\n",
      " |                     '2018-03-02 09:00:00-05:00',\n",
      " |                     '2018-03-03 09:00:00-05:00'],\n",
      " |                    dtype='datetime64[ns, US/Eastern]', freq='D')\n",
      " |      \n",
      " |      With the ``tz=None``, we can remove the time zone information\n",
      " |      while keeping the local time (not converted to UTC):\n",
      " |      \n",
      " |      >>> tz_aware.tz_localize(None)\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',\n",
      " |                     '2018-03-03 09:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas can\n",
      " |      infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',\n",
      " |      ...                               '2018-10-28 02:00:00',\n",
      " |      ...                               '2018-10-28 02:30:00',\n",
      " |      ...                               '2018-10-28 02:00:00',\n",
      " |      ...                               '2018-10-28 02:30:00',\n",
      " |      ...                               '2018-10-28 03:00:00',\n",
      " |      ...                               '2018-10-28 03:30:00']))\n",
      " |      >>> s.dt.tz_localize('CET', ambiguous='infer')\n",
      " |      0   2018-10-28 01:30:00+02:00\n",
      " |      1   2018-10-28 02:00:00+02:00\n",
      " |      2   2018-10-28 02:30:00+02:00\n",
      " |      3   2018-10-28 02:00:00+01:00\n",
      " |      4   2018-10-28 02:30:00+01:00\n",
      " |      5   2018-10-28 03:00:00+01:00\n",
      " |      6   2018-10-28 03:30:00+01:00\n",
      " |      dtype: datetime64[ns, CET]\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',\n",
      " |      ...                               '2018-10-28 02:36:00',\n",
      " |      ...                               '2018-10-28 03:46:00']))\n",
      " |      >>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      0   2015-03-29 03:00:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, Europe/Warsaw]\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backwards with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backwards'`.\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',\n",
      " |      ...                               '2015-03-29 03:30:00']))\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      0   2015-03-29 03:00:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      0   2015-03-29 01:59:59.999999999+01:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      0   2015-03-29 03:30:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  freq\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  date\n",
      " |      Returns numpy array of python datetime.date objects (namely, the date\n",
      " |      part of Timestamps without timezone information).\n",
      " |  \n",
      " |  day\n",
      " |      The month as January=1, December=12.\n",
      " |  \n",
      " |  dayofweek\n",
      " |      The day of the week with Monday=0, Sunday=6.\n",
      " |      \n",
      " |      Return the day of the week. It is assumed the week starts on\n",
      " |      Monday, which is denoted by 0 and ends on Sunday which is denoted\n",
      " |      by 6. This method is available on both Series with datetime\n",
      " |      values (using the `dt` accessor) or DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or Index\n",
      " |          Containing integers indicating the day number.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dt.dayofweek : Alias.\n",
      " |      Series.dt.weekday : Alias.\n",
      " |      Series.dt.day_name : Returns the name of the day of the week.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n",
      " |      >>> s.dt.dayofweek\n",
      " |      2016-12-31    5\n",
      " |      2017-01-01    6\n",
      " |      2017-01-02    0\n",
      " |      2017-01-03    1\n",
      " |      2017-01-04    2\n",
      " |      2017-01-05    3\n",
      " |      2017-01-06    4\n",
      " |      2017-01-07    5\n",
      " |      2017-01-08    6\n",
      " |      Freq: D, dtype: int64\n",
      " |  \n",
      " |  dayofyear\n",
      " |      The ordinal day of the year.\n",
      " |  \n",
      " |  days_in_month\n",
      " |      The number of days in the month.\n",
      " |  \n",
      " |  daysinmonth\n",
      " |      The number of days in the month.\n",
      " |  \n",
      " |  hour\n",
      " |      The hours of the datetime.\n",
      " |  \n",
      " |  is_leap_year\n",
      " |      Boolean indicator if the date belongs to a leap year.\n",
      " |      \n",
      " |      A leap year is a year, which has 366 days (instead of 365) including\n",
      " |      29th of February as an intercalary day.\n",
      " |      Leap years are years which are multiples of four with the exception\n",
      " |      of years divisible by 100 but not by 400.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or ndarray\n",
      " |           Booleans indicating if dates belong to a leap year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2012-01-01\", \"2015-01-01\", freq=\"Y\")\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],\n",
      " |                    dtype='datetime64[ns]', freq='A-DEC')\n",
      " |      >>> idx.is_leap_year\n",
      " |      array([ True, False, False], dtype=bool)\n",
      " |      \n",
      " |      >>> dates = pd.Series(idx)\n",
      " |      >>> dates_series\n",
      " |      0   2012-12-31\n",
      " |      1   2013-12-31\n",
      " |      2   2014-12-31\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> dates_series.dt.is_leap_year\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  is_month_end\n",
      " |      Indicates whether the date is the last day of the month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or array\n",
      " |          For Series, returns a Series with boolean values.\n",
      " |          For DatetimeIndex, returns a boolean array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_month_start : Return a boolean indicating whether the date\n",
      " |          is the first day of the month.\n",
      " |      is_month_end : Return a boolean indicating whether the date\n",
      " |          is the last day of the month.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n",
      " |      >>> s\n",
      " |      0   2018-02-27\n",
      " |      1   2018-02-28\n",
      " |      2   2018-03-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> s.dt.is_month_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      >>> s.dt.is_month_end\n",
      " |      0    False\n",
      " |      1    True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2018-02-27\", periods=3)\n",
      " |      >>> idx.is_month_start\n",
      " |      array([False, False, True])\n",
      " |      >>> idx.is_month_end\n",
      " |      array([False, True, False])\n",
      " |  \n",
      " |  is_month_start\n",
      " |      Indicates whether the date is the first day of the month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or array\n",
      " |          For Series, returns a Series with boolean values.\n",
      " |          For DatetimeIndex, returns a boolean array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_month_start : Return a boolean indicating whether the date\n",
      " |          is the first day of the month.\n",
      " |      is_month_end : Return a boolean indicating whether the date\n",
      " |          is the last day of the month.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n",
      " |      >>> s\n",
      " |      0   2018-02-27\n",
      " |      1   2018-02-28\n",
      " |      2   2018-03-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> s.dt.is_month_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      >>> s.dt.is_month_end\n",
      " |      0    False\n",
      " |      1    True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2018-02-27\", periods=3)\n",
      " |      >>> idx.is_month_start\n",
      " |      array([False, False, True])\n",
      " |      >>> idx.is_month_end\n",
      " |      array([False, True, False])\n",
      " |  \n",
      " |  is_quarter_end\n",
      " |      Indicator for whether the date is the last day of a quarter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_quarter_end : Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      quarter : Return the quarter of the date.\n",
      " |      is_quarter_start : Similar property indicating the quarter start.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n",
      " |      ...                    periods=4)})\n",
      " |      >>> df.assign(quarter=df.dates.dt.quarter,\n",
      " |      ...           is_quarter_end=df.dates.dt.is_quarter_end)\n",
      " |             dates  quarter    is_quarter_end\n",
      " |      0 2017-03-30        1             False\n",
      " |      1 2017-03-31        1              True\n",
      " |      2 2017-04-01        2             False\n",
      " |      3 2017-04-02        2             False\n",
      " |      \n",
      " |      >>> idx = pd.date_range('2017-03-30', periods=4)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_quarter_end\n",
      " |      array([False,  True, False, False])\n",
      " |  \n",
      " |  is_quarter_start\n",
      " |      Indicator for whether the date is the first day of a quarter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_quarter_start : Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      quarter : Return the quarter of the date.\n",
      " |      is_quarter_end : Similar property for indicating the quarter start.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n",
      " |      ...                   periods=4)})\n",
      " |      >>> df.assign(quarter=df.dates.dt.quarter,\n",
      " |      ...           is_quarter_start=df.dates.dt.is_quarter_start)\n",
      " |             dates  quarter  is_quarter_start\n",
      " |      0 2017-03-30        1             False\n",
      " |      1 2017-03-31        1             False\n",
      " |      2 2017-04-01        2              True\n",
      " |      3 2017-04-02        2             False\n",
      " |      \n",
      " |      >>> idx = pd.date_range('2017-03-30', periods=4)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_quarter_start\n",
      " |      array([False, False,  True, False])\n",
      " |  \n",
      " |  is_year_end\n",
      " |      Indicate whether the date is the last day of the year.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_year_start : Similar property indicating the start of the year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n",
      " |      >>> dates\n",
      " |      0   2017-12-30\n",
      " |      1   2017-12-31\n",
      " |      2   2018-01-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> dates.dt.is_year_end\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-12-30\", periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_year_end\n",
      " |      array([False,  True, False])\n",
      " |  \n",
      " |  is_year_start\n",
      " |      Indicate whether the date is the first day of a year.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_year_end : Similar property indicating the last day of the year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n",
      " |      >>> dates\n",
      " |      0   2017-12-30\n",
      " |      1   2017-12-31\n",
      " |      2   2018-01-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> dates.dt.is_year_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-12-30\", periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_year_start\n",
      " |      array([False, False,  True])\n",
      " |  \n",
      " |  microsecond\n",
      " |      The microseconds of the datetime.\n",
      " |  \n",
      " |  minute\n",
      " |      The minutes of the datetime.\n",
      " |  \n",
      " |  month\n",
      " |      The month as January=1, December=12.\n",
      " |  \n",
      " |  nanosecond\n",
      " |      The nanoseconds of the datetime.\n",
      " |  \n",
      " |  quarter\n",
      " |      The quarter of the date.\n",
      " |  \n",
      " |  second\n",
      " |      The seconds of the datetime.\n",
      " |  \n",
      " |  time\n",
      " |      Returns numpy array of datetime.time. The time part of the Timestamps.\n",
      " |  \n",
      " |  timetz\n",
      " |      Returns numpy array of datetime.time also containing timezone\n",
      " |      information. The time part of the Timestamps.\n",
      " |  \n",
      " |  tz\n",
      " |      Return timezone, if any.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime.tzinfo, pytz.tzinfo.BaseTZInfo, dateutil.tz.tz.tzfile, or None\n",
      " |          Returns None when the array is tz-naive.\n",
      " |  \n",
      " |  week\n",
      " |      The week ordinal of the year.\n",
      " |  \n",
      " |  weekday\n",
      " |      The day of the week with Monday=0, Sunday=6.\n",
      " |      \n",
      " |      Return the day of the week. It is assumed the week starts on\n",
      " |      Monday, which is denoted by 0 and ends on Sunday which is denoted\n",
      " |      by 6. This method is available on both Series with datetime\n",
      " |      values (using the `dt` accessor) or DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or Index\n",
      " |          Containing integers indicating the day number.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dt.dayofweek : Alias.\n",
      " |      Series.dt.weekday : Alias.\n",
      " |      Series.dt.day_name : Returns the name of the day of the week.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n",
      " |      >>> s.dt.dayofweek\n",
      " |      2016-12-31    5\n",
      " |      2017-01-01    6\n",
      " |      2017-01-02    0\n",
      " |      2017-01-03    1\n",
      " |      2017-01-04    2\n",
      " |      2017-01-05    3\n",
      " |      2017-01-06    4\n",
      " |      2017-01-07    5\n",
      " |      2017-01-08    6\n",
      " |      Freq: D, dtype: int64\n",
      " |  \n",
      " |  weekofyear\n",
      " |      The week ordinal of the year.\n",
      " |  \n",
      " |  year\n",
      " |      The year of the datetime.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Properties:\n",
      " |  \n",
      " |  __init__(self, data, orig)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.PandasDelegate:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return a string representation for a particular object.\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __annotations__ = {'_accessors': typing.Set[str], '_deprecations': typ...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.NoNewAttributesMixin:\n",
      " |  \n",
      " |  __setattr__(self, key, value)\n",
      " |      Implement setattr(self, name, value).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r=pd.to_datetime(pd.Series([\"2020-11-12\",\"2020-11-11\"]))\n",
    "help(r.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "dtype: int64\n",
      "\n",
      "0     0\n",
      "1     1\n",
      "2     4\n",
      "3     9\n",
      "4    16\n",
      "5    25\n",
      "6    36\n",
      "7    49\n",
      "8    64\n",
      "9    81\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "s1 = pd.Series(range(10))\n",
    "print(s1)\n",
    "\n",
    "print()\n",
    "s2 = s1**2\n",
    "print(s2)\n",
    "\n",
    "plt.plot(s1,c='r',alpha=0.5, marker='o', linestyle='dashed',linewidth=2, markersize=12) # alpha => transparency float : [0-1]\n",
    "plt.plot(s2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1307, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill na with mean for fare and age column column.\n",
    "df.fillna({\"fare\":df.fare.mean(),\"age\":df.age.mean()},inplace=True)\n",
    "df.count()\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '_AXIS_ALIASES', '_AXIS_IALIASES', '_AXIS_LEN', '_AXIS_NAMES', '_AXIS_NUMBERS', '_AXIS_ORDERS', '_AXIS_REVERSED', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_add_numeric_operations', '_add_series_or_dataframe_operations', '_agg_by_level', '_agg_examples_doc', '_agg_summary_and_see_also_doc', '_aggregate', '_aggregate_multiple_funcs', '_align_frame', '_align_series', '_box_col_values', '_box_item_values', '_builtin_table', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_combine_frame', '_combine_match_index', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_dict_from', '_construct_axes_from_arguments', '_construct_result', '_constructor', '_constructor_expanddim', '_constructor_sliced', '_convert', '_count_level', '_create_indexer', '_cython_table', '_deprecations', '_dir_additions', '_dir_deletions', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_from_arrays', '_from_axes', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_cleaned_column_resolvers', '_get_cython_func', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_get_values', '_getitem_bool_array', '_getitem_multilevel', '_gotitem', '_iget_item_cache', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_internal_get_values', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cached', '_is_copy', '_is_datelike_mixed_type', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_numeric_mixed_type', '_is_view', '_ix', '_ixs', '_join_compat', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_needs_reindex_multi', '_obj_with_exclusions', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_columns', '_reindex_index', '_reindex_multi', '_reindex_with_indexers', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_series', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_is_copy', '_set_item', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_setup_axes', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_take_with_is_copy', '_to_dict_of_blocks', '_try_aggregate_string_function', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', '_xs', 'abs', 'add', 'add_prefix', 'add_suffix', 'age', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'between_time', 'bfill', 'bool', 'boxplot', 'clip', 'columns', 'combine', 'combine_first', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'embarked', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'fare', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'floordiv', 'from_dict', 'from_records', 'ge', 'gender', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isin', 'isna', 'isnull', 'items', 'iteritems', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lookup', 'lt', 'mad', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'name', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'parch', 'pclass', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_index', 'shape', 'shift', 'sibsp', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'survived', 'swapaxes', 'swaplevel', 'tail', 'take', 'ticket', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unstack', 'update', 'values', 'var', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "print(dir(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the dataframe to a csv file 'titanic_filtered.csv'.\n",
    "df.to_csv(\"titanic_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for surviced column replace 0 with D and 1 with A\n",
    "df.survived=df.survived.replace([0,1],[\"D\",\"A\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "A    498\n",
       "D    809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the frequency of different values in survived column\n",
    "sur_grp=df.groupby(\"survived\")\n",
    "sur_grp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived  gender\n",
       "A         female    337\n",
       "          male      161\n",
       "D         female    127\n",
       "          male      682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group by gender and survived and see the counts in each category\n",
    "grp=df.groupby([\"survived\",\"gender\"])\n",
    "grp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass\n",
       "1    321\n",
       "2    277\n",
       "3    709\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find different pclass and no of people in each class\n",
    "grp_pclass=df.groupby(\"pclass\")\n",
    "grp_pclass.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80.     76.     74.     ...  0.4167  0.3333  0.1667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14      80.0\n",
       "61      76.0\n",
       "1235    74.0\n",
       "135     71.0\n",
       "9       71.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find top 5 people with highest values of age. Count no of male and females in the top 5\n",
    "df_age=df.age.sort_values(ascending=False)\n",
    "print(df_age.values)\n",
    "df_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '_AXIS_ALIASES', '_AXIS_IALIASES', '_AXIS_LEN', '_AXIS_NAMES', '_AXIS_NUMBERS', '_AXIS_ORDERS', '_AXIS_REVERSED', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_add_numeric_operations', '_add_series_or_dataframe_operations', '_agg_by_level', '_agg_examples_doc', '_agg_see_also_doc', '_aggregate', '_aggregate_multiple_funcs', '_align_frame', '_align_series', '_binop', '_box_item_values', '_builtin_table', '_can_hold_na', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_dict_from', '_construct_axes_from_arguments', '_constructor', '_constructor_expanddim', '_constructor_sliced', '_convert', '_convert_dtypes', '_create_indexer', '_cython_table', '_deprecations', '_dir_additions', '_dir_deletions', '_drop_axis', '_drop_labels_or_levels', '_find_valid_index', '_from_axes', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_cleaned_column_resolvers', '_get_cython_func', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_get_values', '_get_values_tuple', '_get_with', '_gotitem', '_iget_item_cache', '_index', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_init_dict', '_init_mgr', '_internal_get_values', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cached', '_is_copy', '_is_datelike_mixed_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_numeric_mixed_type', '_is_view', '_ix', '_ixs', '_map_values', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_ndarray_values', '_needs_reindex_multi', '_obj_with_exclusions', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_indexer', '_reindex_multi', '_reindex_with_indexers', '_repr_data_resource_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_is_copy', '_set_item', '_set_labels', '_set_name', '_set_subtyp', '_set_value', '_set_values', '_set_with', '_set_with_engine', '_setup_axes', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_take_with_is_copy', '_to_dict_of_blocks', '_try_aggregate_string_function', '_typ', '_unpickle_series_compat', '_update_inplace', '_validate_dtype', '_values', '_where', '_xs', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'argmax', 'argmin', 'argsort', 'array', 'asfreq', 'asof', 'astype', 'at', 'at_time', 'attrs', 'autocorr', 'axes', 'between', 'between_time', 'bfill', 'bool', 'clip', 'combine', 'combine_first', 'convert_dtypes', 'copy', 'corr', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'divmod', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtype', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'ewm', 'expanding', 'explode', 'factorize', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'floordiv', 'ge', 'get', 'groupby', 'gt', 'hasnans', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'interpolate', 'is_monotonic', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'is_unique', 'isin', 'isna', 'isnull', 'item', 'items', 'iteritems', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lt', 'mad', 'map', 'mask', 'max', 'mean', 'median', 'memory_usage', 'min', 'mod', 'mode', 'mul', 'multiply', 'name', 'nbytes', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pct_change', 'pipe', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'radd', 'rank', 'ravel', 'rdiv', 'rdivmod', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'repeat', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'searchsorted', 'sem', 'set_axis', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'std', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_frame', 'to_hdf', 'to_json', 'to_latex', 'to_list', 'to_markdown', 'to_numpy', 'to_period', 'to_pickle', 'to_sql', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unique', 'unstack', 'update', 'value_counts', 'values', 'var', 'view', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "print(dir(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_age_of_survived_Male 80.0\n",
      "max_age_of_survived_Female 76.0\n"
     ]
    }
   ],
   "source": [
    "#find max age male and female who survived\n",
    "df_sur_max_age = df.groupby([\"survived\",\"gender\"])\n",
    "df_sur_max_age.size()\n",
    "print(\"max_age_of_survived_Male\",df_sur_max_age.get_group(('A','male')).age.max())\n",
    "print(\"max_age_of_survived_Female\",df_sur_max_age.get_group(('A','female')).age.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_accessors', '_add_numeric_operations', '_agg_examples_doc', '_agg_see_also_doc', '_aggregate', '_aggregate_frame', '_aggregate_item_by_item', '_aggregate_multiple_funcs', '_apply_filter', '_apply_to_column_groupbys', '_apply_whitelist', '_assure_grouper', '_bool_agg', '_builtin_table', '_choose_path', '_concat_objects', '_constructor', '_cumcount_array', '_cython_agg_blocks', '_cython_agg_general', '_cython_table', '_cython_transform', '_define_paths', '_deprecations', '_dir_additions', '_dir_deletions', '_fill', '_get_cython_func', '_get_cythonized_result', '_get_data_to_aggregate', '_get_index', '_get_indices', '_gotitem', '_group_selection', '_insert_inaxis_grouper_inplace', '_internal_names', '_internal_names_set', '_is_builtin_func', '_iterate_column_groupbys', '_iterate_slices', '_make_wrapper', '_obj_with_exclusions', '_python_agg_general', '_python_apply_general', '_reindex_output', '_reset_cache', '_reset_group_selection', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_group_selection', '_set_result_index_ordered', '_transform_fast', '_transform_general', '_transform_item_by_item', '_transform_should_cast', '_try_aggregate_string_function', '_try_cast', '_wrap_agged_blocks', '_wrap_aggregated_output', '_wrap_applied_output', '_wrap_frame_output', '_wrap_transformed_output', 'age', 'agg', 'aggregate', 'all', 'any', 'apply', 'backfill', 'bfill', 'boxplot', 'corr', 'corrwith', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtypes', 'embarked', 'expanding', 'fare', 'ffill', 'fillna', 'filter', 'first', 'gender', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'last', 'mad', 'max', 'mean', 'median', 'min', 'name', 'ndim', 'ngroup', 'ngroups', 'nth', 'nunique', 'ohlc', 'pad', 'parch', 'pclass', 'pct_change', 'pipe', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sem', 'shift', 'sibsp', 'size', 'skew', 'std', 'sum', 'survived', 'tail', 'take', 'ticket', 'transform', 'tshift', 'var']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.34</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.96</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.48</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>Turkula, Mrs. (Hedwig)</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4134</td>\n",
       "      <td>9.59</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>Vartanian, Mr. David</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2658</td>\n",
       "      <td>7.23</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>Whabee, Mrs. George Joseph (Shawneene Abi-Saab)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2688</td>\n",
       "      <td>7.23</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.00</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>Yasbeck, Mrs. Antoni (Selini Alexander)</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.45</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  pclass survived  \\\n",
       "0              0       1        A   \n",
       "1              1       1        A   \n",
       "5              5       1        A   \n",
       "6              6       1        A   \n",
       "8              8       1        A   \n",
       "...          ...     ...      ...   \n",
       "1261        1261       3        A   \n",
       "1277        1277       3        A   \n",
       "1286        1286       3        A   \n",
       "1290        1290       3        A   \n",
       "1300        1300       3        A   \n",
       "\n",
       "                                                 name  gender      age  sibsp  \\\n",
       "0                       Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
       "1                      Allison, Master. Hudson Trevor    male   0.9167      1   \n",
       "5                                 Anderson, Mr. Harry    male  48.0000      0   \n",
       "6                   Andrews, Miss. Kornelia Theodosia  female  63.0000      1   \n",
       "8       Appleton, Mrs. Edward Dale (Charlotte Lamson)  female  53.0000      2   \n",
       "...                                               ...     ...      ...    ...   \n",
       "1261                           Turkula, Mrs. (Hedwig)  female  63.0000      0   \n",
       "1277                             Vartanian, Mr. David    male  22.0000      0   \n",
       "1286  Whabee, Mrs. George Joseph (Shawneene Abi-Saab)  female  38.0000      0   \n",
       "1290                 Wilkes, Mrs. James (Ellen Needs)  female  47.0000      1   \n",
       "1300          Yasbeck, Mrs. Antoni (Selini Alexander)  female  15.0000      1   \n",
       "\n",
       "      parch  ticket    fare embarked  \n",
       "0         0   24160  211.34        S  \n",
       "1         2  113781  151.55        S  \n",
       "5         0   19952   26.55        S  \n",
       "6         0   13502   77.96        S  \n",
       "8         0   11769   51.48        S  \n",
       "...     ...     ...     ...      ...  \n",
       "1261      0    4134    9.59        S  \n",
       "1277      0    2658    7.23        C  \n",
       "1286      0    2688    7.23        C  \n",
       "1290      0  363272    7.00        S  \n",
       "1300      0    2659   14.45        C  \n",
       "\n",
       "[498 rows x 11 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(df_sur_max_age))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average age of male 30.430715521707075\n",
      "Average age of female 28.79593080165825\n"
     ]
    }
   ],
   "source": [
    "#get average age by gender\n",
    "gen_avg_age_male = df.groupby(\"gender\").get_group('male').age.mean()\n",
    "print(\"Average age of male\",gen_avg_age_male)\n",
    "gen_avg_age_female = df.groupby(\"gender\").get_group('female').age.mean()\n",
    "print(\"Average age of female\",gen_avg_age_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived people avg age 28.97471128395037\n",
      "Not survived people avg age 30.38936817968011\n"
     ]
    }
   ],
   "source": [
    "#get average age by people survived vs not-survived\n",
    "sur_avg_age = df.groupby(\"survived\").get_group(\"A\").age.mean()\n",
    "Not_sur_avg_age = df.groupby(\"survived\").get_group(\"D\").age.mean()\n",
    "print(\"Survived people avg age\",sur_avg_age)\n",
    "print(\"Not survived people avg age\",Not_sur_avg_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
